{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Questions\n",
    "\n",
    "> **Things to remember**:\n",
    "> - The questions must be stated, justified, and an additional question is proposed above the minimum of 2 or at least outlined with a study afterward (sometimes these extra questions are not made explicit but are still studied).\n",
    "> - We should make an exploratory data analysis (EDA) for each question.\n",
    "> - We must apply more than one advanced technique (statistical test or data mining algorithm). For example, one advanced technique per question.\n",
    "> - Conclusions must be consistent with the results and understandable, answering the questions of interest raised. Also, we have to interpret the conclusions within the context of the dataset’s domain (e.g., therefore, treatment X is better than Y for treating fever, and the drug guides should be modified to improve the treatment of this type of symptom).\n",
    "> - We should include more than one correct and coherent visualization for the type of information being presented, making proper use of visual elements. For a higher grade, we should make use of advanced visualizations features of the libraries we use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    ")\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Types\n",
    "from polars.dataframe.frame import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load the cleaned dataset generated in the `01_introduction_and_processing.ipynb` notebook and show its first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data: DataFrame = pl.read_csv(\n",
    "    source=\"../data/cleaned/data.csv\",\n",
    ")\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: What factors influence a country's life expectancy?\n",
    "\n",
    "In order to give an answer to the question *What factors influence a country's life expectancy?*, we will investigate the key factors that influence life expectancy across different countries. Life expectancy is a crucial indicator of a nation’s overall well-being, reflecting healthcare quality, economic conditions, and other factors.\n",
    "\n",
    "Understanding the determinants of life expectancy is essential for policymakers, healthcare professionals, and economists to improve public health strategies and resource allocation. \n",
    "By analyzing global data, this study will identify the most influential factors and their relationships with life expectancy, offering insights into how countries can improve public health outcomes.\n",
    "\n",
    "As a starting point, we will perform a correlation analysis to identify the variables that are most strongly associated with life expectancy. Then, we will select some insteresting variables that could impact life expectancy and perform an association rule mining analysis to identify the most frequent patterns of these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation analysis is a statistical technique that measures the strength and direction of the relationship between two variables. The correlation coefficient ranges from -1 to 1, where -1 indicates a perfect negative correlation, 1 indicates a perfect positive correlation, and 0 indicates no correlation. We are going to create a heatmap to visualize the correlation matrix between variables, paying special attention to the correlation with life expectancy.\n",
    "\n",
    "It is important to emphasize that we will be using the Spearman correlation coefficient. Unlike the Pearson correlation, which assumes a linear relationship, Spearman focuses on the ranks or positions of the data rather than their exact values. This is helpful when the data isn't evenly spread out or when the relationship between the variables is more complicated. It allows us to better understand how life expectancy relates to other factors, even if the data is not perfect or has outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns that are not needed for the correlation matrix\n",
    "corr_data = cleaned_data.drop([\"Country\", \"Abbreviation\", \"Code\", \"Year\"])\n",
    "\n",
    "# Convert the Polars DataFrame to a Pandas DataFrame\n",
    "corr_data = corr_data.to_pandas()\n",
    "\n",
    "# Calculate the correlation matrix using the Spearman correlation coefficient\n",
    "correlation_matrix = corr_data.corr(method=\"spearman\")\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(\n",
    "    data=correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5\n",
    ")\n",
    "plt.title(label=\"Spearmans Correlation Matrix\", fontdict={\"fontsize\": 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the highest correlations obtained and identify if there are variables that could be eliminated due to multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the diagonal with NaN to ignore self-correlations\n",
    "np.fill_diagonal(correlation_matrix.values, np.nan)\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones(correlation_matrix.shape), k=1)\n",
    "\n",
    "# Apply the mask and unstack the upper triangle\n",
    "top_correlations = (\n",
    "    (correlation_matrix * mask).unstack().dropna().sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Print the sorted correlation pairs\n",
    "print(top_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there are some variables that are highly correlated with each other, so we will remove the following variables from the analysis:\n",
    "- Fertility Rate: It will be removed due to its high correlation with the Birth Rate, as both variables reflect similar aspects of demographic dynamics.\n",
    "- Urban population: It will be removed due to its high correlation with Population, as the latter already captures the relevant information about the total population, making the urban variable redundant.\n",
    "- Maternal mortality ratio: It will be removed due to its high correlation with Infant mortality, as both variables are closely related to maternal and infant health and well-being."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove these variables and perform the correlation analysis again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns that are not needed for the correlation matrix\n",
    "corr_data = cleaned_data.drop(\n",
    "    [\n",
    "        \"Country\",\n",
    "        \"Abbreviation\",\n",
    "        \"Code\",\n",
    "        \"Year\",\n",
    "        \"Fertility Rate\",\n",
    "        \"Urban population\",\n",
    "        \"Maternal mortality ratio\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert the Polars DataFrame to a Pandas DataFrame\n",
    "corr_data = corr_data.to_pandas()\n",
    "\n",
    "# Calculate the correlation matrix using the Spearman correlation coefficient\n",
    "correlation_matrix = corr_data.corr(method=\"spearman\")\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(\n",
    "    data=correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5\n",
    ")\n",
    "plt.title(label=\"Spearmans Correlation Matrix\", fontdict={\"fontsize\": 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the highest correlated variables with life expectancy to identify the most influential factors. We will show a plot with the top 5 most positively and negatively correlated variables with life expectancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlations with the target variable\n",
    "correlations = (\n",
    "    correlation_matrix[\"Life expectancy\"]\n",
    "    .drop(\"Life expectancy\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Get the top 5 positive and negative correlations\n",
    "top_positive = correlations.head(5)\n",
    "top_negative = correlations.tail(5)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 3))\n",
    "\n",
    "# Positive correlations plot\n",
    "sns.barplot(x=top_positive.values, y=top_positive.index, ax=axes[0])\n",
    "axes[0].set_title(\"Highest Positive Correlations with Life Expectancy\")\n",
    "axes[0].set_xlabel(\"Spearman Correlation Coefficient\")\n",
    "axes[0].set_ylabel(\"\")\n",
    "\n",
    "# Negative correlations plot\n",
    "sns.barplot(x=top_negative.values, y=top_negative.index, ax=axes[1])\n",
    "axes[1].set_title(\"Highest Negative Correlations with Life Expectancy\")\n",
    "axes[1].set_xlabel(\"Spearman Correlation Coefficient\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, having more physicians per thousand people suggests better healthcare availability, which is linked to longer life expectancy. Higher enrollment in tertiary education may lead to better overall health outcomes, as education is often associated with healthier lifestyle choices and access to healthcare, althought this is also highly correlated with the economic level of a country so no definite conclussion can be taken from hte education. A higher median salary typically reflects better access to resources, leading to improved nutrition and living conditions, which can increase life expectancy. Similarly, higher daily calorie supply from dairy, eggs, and meat points to better nutrition, which is also associated with improved life expectancy.\n",
    "\n",
    "On the negative side, a higher birth rate often indicates greater strain on healthcare systems and resources, and it's often associated with lower income countries, leading to poorer health outcomes and shorter life expectancy. Similarly, higher infant mortality reflects inadequate healthcare and living conditions, contributing to lower life expectancy. While the correlation with the Consumer Price Index (CPI) is negative, it is not very strong, meaning that rising living costs may have a moderate impact on life expectancy, particularly by making healthcare and basic needs less affordable. The are no more remarkable negative correlations with life expectancy.\n",
    "\n",
    "While the correlation matrix provides useful insights into the relationships between life expectancy and various factors, it's important to interpret these results carefully, as correlation does not imply causation. To gain a deeper understanding of the factors influencing life expectancy, we will perform an association rule analysis as our next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Before taking any further guesses on the impact of the different variables on life expectancy, we will plot the values of this variables across the world and make use of the external knowledge or biases we have to establish our hypostheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    cleaned_data.to_pandas(),\n",
    "    locations=\"Country\",\n",
    "    locationmode=\"country names\",\n",
    "    color=\"Life expectancy\",\n",
    "    hover_name=\"Country\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    projection=\"natural earth\",\n",
    "    title=\"Life expectancy per country\",\n",
    ")\n",
    "fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 50, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rules\n",
    "\n",
    "Association rules are a powerful technique for discovering relationships between variables in large datasets. They are widely used in market basket analysis, where the goal is to identify patterns in consumer behavior. In this study, we will apply association rules to identify patterns between different variables and life expectancy. This method will allow us to discover meaningful patterns, such as whether healthcare expenditures are strongly associated with increased life expectancy or if specific economic conditions correlate with lower life expectancy.\n",
    "\n",
    "To achieve this, we should select columns that are most likely to have a meaningful relationship with life expectancy, either directly or through indirect factors. Let's consider the following variables:\n",
    "\n",
    "1. **Life expectancy**: The target variable that we aim to analyze and understand in relation to other factors. It represents the average number of years a person is expected to live.\n",
    "\n",
    "2. **Out of pocket health expenditure**: Higher out-of-pocket health expenditure can indicate a lack of access to affordable healthcare, which may negatively affect life expectancy, as individuals may delay or forgo necessary medical treatment.\n",
    "\n",
    "3. **Physicians per thousand**: The more physicians available per thousand people, the better the healthcare access, which is expected to positively influence life expectancy by improving early diagnosis, treatment, and overall healthcare quality.\n",
    "\n",
    "4. **Daily total caloric ingestion**: Sufficient caloric intake is essential for health, but excessive or poor-quality caloric consumption (such as from unhealthy sources) can lead to chronic diseases like obesity, which could lower life expectancy. Balanced and adequate caloric intake is typically associated with better health outcomes.\n",
    "\n",
    "5. **GDP per capita**: A higher GDP per capita generally correlates with more resources for healthcare, education, and infrastructure, all of which contribute to better living conditions and longer life expectancy by improving overall health and access to essential services. Note that we don't have the GDP per capita in the dataset, but we can calculate it by dividing the GDP by the population.\n",
    "\n",
    "6. **Unemployment rate**: High unemployment rates are often associated with increased stress, poverty, and reduced access to healthcare, which could negatively affect life expectancy as these factors can lead to poor mental and physical health outcomes.\n",
    "\n",
    "7. **Urban population percentage**: Urban areas typically have better healthcare infrastructure, sanitation, and access to medical services, all of which are expected to positively influence life expectancy, as residents tend to have better health outcomes than those in rural areas with fewer resources. Note that we don't have the urban population percentage in the dataset, but we can calculate it by dividing the urban population by the total population.\n",
    "\n",
    "8. **CO2 emissions per capita**: High levels of CO2 emissions often indicate higher levels of air pollution, which can have negative health effects, such as respiratory and cardiovascular diseases, thereby potentially lowering life expectancy in polluted areas. Note that we don't have the CO2 emissions per capita in the dataset, but we can calculate it by dividing the CO2 emissions by the population.\n",
    "\n",
    "We made these assumtion based on the data and visualization seen so far, as well as \"facts\" we are taught across our own life experiences. But are these assumptions be correct? Let's find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we don't have a GDP per capita column in our dataset, but we can calculate it by dividing the GDP by the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GDP per capita\n",
    "cleaned_data = cleaned_data.with_columns(\n",
    "    (pl.col(\"GDP\") / pl.col(\"Population\")).alias(\"GDP per capita\")\n",
    ")\n",
    "\n",
    "# Drop GDP column\n",
    "cleaned_data = cleaned_data.drop([\"GDP\"])\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we don't have a CO2 emissions per capita column in our dataset, but we can calculate it by dividing the CO2 emissions by the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change unit from kilotonnes to tonnes\n",
    "cleaned_data = cleaned_data.with_columns(\n",
    "    (pl.col(\"Co2-Emissions\") * 1_000).alias(\"Co2-Emissions\")\n",
    ")\n",
    "\n",
    "# Calculate CO2 emissions per capita\n",
    "cleaned_data = cleaned_data.with_columns(\n",
    "    (pl.col(\"Co2-Emissions\") / pl.col(\"Population\")).alias(\"CO2 emissions per capita\")\n",
    ")\n",
    "\n",
    "# Drop CO2 emissions column\n",
    "cleaned_data = cleaned_data.drop([\"Co2-Emissions\"])\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if CO2 emissions per capita have been calculated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show if there are negative values for CO2 emissions per capita\n",
    "data_incorrect_co2 = cleaned_data.filter(pl.col(\"CO2 emissions per capita\") < 0)\n",
    "data_incorrect_co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also don't have the urban population percentage in the dataset, but we can calculate it by dividing the urban population by the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate urban population percentage\n",
    "cleaned_data = cleaned_data.with_columns(\n",
    "    (pl.col(\"Urban population\") / pl.col(\"Population\") * 100).alias(\n",
    "        \"Urban population percentage\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop Urban population and Population columns\n",
    "cleaned_data = cleaned_data.drop([\"Urban population\", \"Population\"])\n",
    "\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the percentages have been calculated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show if there are percentages greater than 100\n",
    "data_incorrect_percentages = cleaned_data.filter(\n",
    "    pl.col(\"Urban population percentage\") > 100\n",
    ")\n",
    "data_incorrect_percentages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are three urban population percentage values that are greater than 100%. This was caused by an incorrect estimation of the urban population during preprocessing. We will address this issue by eliminating these rows from the dataset, because we don't have reliable data to correct these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with percentages greater than 100\n",
    "data = cleaned_data.filter(pl.col(\"Urban population percentage\") <= 100)\n",
    "\n",
    "# Show number of rows\n",
    "print(f\"Number of rows: {data.height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to be analyzed\n",
    "data = cleaned_data.select(\n",
    "    [\n",
    "        \"Life expectancy\",\n",
    "        \"Out of pocket health expenditure\",\n",
    "        \"Physicians per thousand\",\n",
    "        \"Daily total caloric ingestion\",\n",
    "        \"GDP per capita\",\n",
    "        \"Unemployment rate\",\n",
    "        \"Urban population percentage\",\n",
    "        \"CO2 emissions per capita\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since association rule mining works better with categorical data, we need to convert continuous numerical variables into categorical ones. We are going to define three categories for each variable. In order to decide the thresholds for these categories, we will analyze each column's main statistics and distribution. As a standard practice, we will consider the 33rd and 66th percentiles as references to establish thresholds for defining the categories, but we will adjust them so that the distribution in categories represents reality in the best possible way.\n",
    "\n",
    "Next, we will present some statistics and the histograms of the variables to help define the categories. It's important to note that some of these distributions may not follow a normal distribution, but this isn't an issue, as we are defining categories based on percentiles. This approach ensures that the samples are evenly distributed across the categories, mitigating the impact of non-normal distributions, which could bias the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Life expectancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "life_expectancy_stats = data[\"Life expectancy\"].describe()\n",
    "print(life_expectancy_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Life expectancy\"].quantile(0.33)\n",
    "q66 = data[\"Life expectancy\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "life_expectancy_values = data[\"Life expectancy\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(life_expectancy_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"Life Expectancy Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Life Expectancy\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results obtained, we will define the following categories for life expectancy:\n",
    "\n",
    "- Low: less than 70 years\n",
    "- Medium: between 70 and 77 years\n",
    "- High: more than 77 years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out of pocket health expenditure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "out_of_pocket_health_expenditure_stats = data[\n",
    "    \"Out of pocket health expenditure\"\n",
    "].describe()\n",
    "print(out_of_pocket_health_expenditure_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Out of pocket health expenditure\"].quantile(0.33)\n",
    "q66 = data[\"Out of pocket health expenditure\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "out_of_pocket_health_expenditure_values = data[\n",
    "    \"Out of pocket health expenditure\"\n",
    "].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(\n",
    "    out_of_pocket_health_expenditure_values, bins=20, kde=True, edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "plt.title(\"Out of Pocket Health Expenditure Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Out of Pocket Health Expenditure\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 66th percentile of out-of-pocket health expenditure is 38.8%, but we will not consider this value as the threshold for the highest category, as it would mean that paying less than the half of the health expenditure out of pocket is considered high. Instead, we will consider a value of 50% as the threshold for the highest category. Therefore, we will define the following categories for out-of-pocket health expenditure:\n",
    "\n",
    "- Low: less than 22%\n",
    "- Medium: between 22% and 50%\n",
    "- High: more than 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Physicians per thousand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "physicians_per_thousand_stats = data[\"Physicians per thousand\"].describe()\n",
    "print(physicians_per_thousand_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Physicians per thousand\"].quantile(0.33)\n",
    "q66 = data[\"Physicians per thousand\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "physicians_per_thousand_values = data[\"Physicians per thousand\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(physicians_per_thousand_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"Physicians per Thousand Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Physicians per Thousand\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results obtained, we will define the following categories for physicians per thousand:\n",
    "\n",
    "- Few: less than 0.75 physicians\n",
    "- Moderate: between 0.75 and 2.5 physicians\n",
    "- Many: more than 2.5 physicians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daily total caloric ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "daily_total_caloric_ingestion_stats = data[\"Daily total caloric ingestion\"].describe()\n",
    "print(daily_total_caloric_ingestion_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Daily total caloric ingestion\"].quantile(0.33)\n",
    "q66 = data[\"Daily total caloric ingestion\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "daily_total_caloric_ingestion_values = data[\"Daily total caloric ingestion\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(daily_total_caloric_ingestion_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"Daily Total Caloric Ingestion Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Daily Total Caloric Ingestion\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been doing some research on the Internet, and we found that the most recommended daily caloric intake is 2000 calories for an average woman and 2500 calories for an average man, like it is stated in [[1]](https://www.nhs.uk/live-well/healthy-weight/managing-your-weight/understanding-calories/#:~:text=an%20average%20man%20needs%202%2C500,needs%202%2C000kcal%20a%20day). The 33th percentile we have obtained is 2738 calories, which is considerably higher than the recommended intake, so we will consider a lower value as the threshold which divides the lowest and medium categories. Therefore, we will define the following categories for daily total caloric ingestion:\n",
    "\n",
    "- Low: less than 2500 calories\n",
    "- Medium: between 2500 and 3200 calories\n",
    "- High: more than 3200 calories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unemployment rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "unemployment_rate_stats = data[\"Unemployment rate\"].describe()\n",
    "print(unemployment_rate_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Unemployment rate\"].quantile(0.33)\n",
    "q66 = data[\"Unemployment rate\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "unemployment_rate_values = data[\"Unemployment rate\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(unemployment_rate_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"Unemployment Rate Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Unemployment Rate\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several countries with an unemployment rate of 15% or higher, which is considered very high. The 66th percentile of the unemployment rate is around 7%, but it would be unfair to consider that a country with an unemployment rate of 7% is in the same category as some other countries that duplicate this value. Therefore, we will consider a value of 10% as the threshold for the highest category. The categories for the unemployment rate will be defined as follows:\n",
    "\n",
    "- Low: less than 4%\n",
    "- Medium: between 4% and 10%\n",
    "- High: more than 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GDP per capita**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "gdp_per_capita_stats = data[\"GDP per capita\"].describe()\n",
    "print(gdp_per_capita_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"GDP per capita\"].quantile(0.33)\n",
    "q66 = data[\"GDP per capita\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "gdp_per_capita_values = data[\"GDP per capita\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(gdp_per_capita_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"GDP per Capita Distribution\", fontsize=14)\n",
    "plt.xlabel(\"GDP per Capita\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results obtained, we will define the following categories for GDP per capita:\n",
    "\n",
    "- Low: less than 3000 USD\n",
    "- Medium: between 3000 and 11000 USD\n",
    "- High: more than 11000 USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Co2-Emissions per capita**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "co2_emissions_per_capita_stats = data[\"CO2 emissions per capita\"].describe()\n",
    "print(co2_emissions_per_capita_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"CO2 emissions per capita\"].quantile(0.33)\n",
    "q66 = data[\"CO2 emissions per capita\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "co2_emissions_per_capita_values = data[\"CO2 emissions per capita\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(co2_emissions_per_capita_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"CO2 Emissions per Capita Distribution\", fontsize=14)\n",
    "plt.xlabel(\"CO2 Emissions per Capita\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will consider the mean value as a reference to establish the thresholds. The mean is 4.2 tons per capita, so we will consider the following categories for CO2 emissions per capita:\n",
    "\n",
    "- Low: less than 3 tons per capita\n",
    "- Medium: between 3 and 6 tons per capita\n",
    "- High: more than 6 tons per capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Urban population percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "urban_population_percentage_stats = data[\"Urban population percentage\"].describe()\n",
    "print(urban_population_percentage_stats)\n",
    "\n",
    "# Calculate q33 and q66\n",
    "q33 = data[\"Urban population percentage\"].quantile(0.33)\n",
    "q66 = data[\"Urban population percentage\"].quantile(0.66)\n",
    "print(f\"q33: {q33}\")\n",
    "print(f\"q66: {q66}\")\n",
    "\n",
    "# Plot histogram\n",
    "urban_population_percentage_values = data[\"Urban population percentage\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(urban_population_percentage_values, bins=20, kde=True, edgecolor=\"black\")\n",
    "\n",
    "plt.title(\"Urban Population Percentage Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Urban Population Percentage\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results obtained, we will define the following categories for urban population percentage:\n",
    "\n",
    "- Low: less than 50%\n",
    "- Medium: between 50% and 70%\n",
    "- High: more than 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After establishing the categories and thresholds for each variable, we are set to perform the transformation of numerical variables into categorical ones. We will substitute the numerical columns with their corresponding categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize continuous variables into categories\n",
    "discretized_data = data.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col(\"Life expectancy\") < 70)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"Life expectancy\").is_between(70, 77))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"Life_expectancy_category\"),\n",
    "        pl.when(pl.col(\"Out of pocket health expenditure\") < 22)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"Out of pocket health expenditure\").is_between(22, 50))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"Out_of_pocket_category\"),\n",
    "        pl.when(pl.col(\"Physicians per thousand\") < 0.75)\n",
    "        .then(pl.lit(\"Few\"))\n",
    "        .when(pl.col(\"Physicians per thousand\").is_between(0.75, 2.5))\n",
    "        .then(pl.lit(\"Moderate\"))\n",
    "        .otherwise(pl.lit(\"Many\"))\n",
    "        .alias(\"Physicians_category\"),\n",
    "        pl.when(pl.col(\"Daily total caloric ingestion\") < 2500)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"Daily total caloric ingestion\").is_between(2500, 3200))\n",
    "        .then(pl.lit(\"Moderate\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"Caloric_ingestion_category\"),\n",
    "        pl.when(pl.col(\"Unemployment rate\") < 4)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"Unemployment rate\").is_between(4, 10))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"Unemployment_category\"),\n",
    "        pl.when(pl.col(\"GDP per capita\") < 3_000)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"GDP per capita\").is_between(3_000, 11_000))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"GDP_per_capita_category\"),\n",
    "        pl.when(pl.col(\"CO2 emissions per capita\") < 3)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"CO2 emissions per capita\").is_between(3, 6))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"CO2_emissions_per_capita_category\"),\n",
    "        pl.when(pl.col(\"Urban population percentage\") < 50)\n",
    "        .then(pl.lit(\"Low\"))\n",
    "        .when(pl.col(\"Urban population percentage\").is_between(50, 70))\n",
    "        .then(pl.lit(\"Medium\"))\n",
    "        .otherwise(pl.lit(\"High\"))\n",
    "        .alias(\"Urban_population_percentage_category\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Drop original columns\n",
    "discretized_data = discretized_data.drop(\n",
    "    [\n",
    "        \"Life expectancy\",\n",
    "        \"Out of pocket health expenditure\",\n",
    "        \"Physicians per thousand\",\n",
    "        \"Daily total caloric ingestion\",\n",
    "        \"Unemployment rate\",\n",
    "        \"GDP per capita\",\n",
    "        \"CO2 emissions per capita\",\n",
    "        \"Urban population percentage\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display transformed data\n",
    "discretized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the distribution of the variables to see how the categories have been defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of categories\n",
    "category_columns = [\n",
    "    \"Life_expectancy_category\",\n",
    "    \"Out_of_pocket_category\",\n",
    "    \"Physicians_category\",\n",
    "    \"Caloric_ingestion_category\",\n",
    "    \"Unemployment_category\",\n",
    "    \"GDP_per_capita_category\",\n",
    "    \"CO2_emissions_per_capita_category\",\n",
    "    \"Urban_population_percentage_category\",\n",
    "]\n",
    "\n",
    "distribution = {col: discretized_data[col].value_counts() for col in category_columns}\n",
    "\n",
    "for col, dist in distribution.items():\n",
    "    print(f\"\\nDistribution of {col}:\")\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will use the `mlxtend` library for association rule mining, we are going to perform One-Hot Encoding to convert the categorical variables into a format suitable for the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the categorized columns\n",
    "categorical_columns = [col for col in discretized_data.columns]\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "data_encoded = discretized_data.select(categorical_columns).to_dummies()\n",
    "\n",
    "# Show the first rows of the one-hot encoded DataFrame\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `mlxtend` library requires a Pandas DataFrame, we convert the Polars DataFrame to Pandas. We will also convert 1 and 0 values to True and False for a better computational performance, as the `mlxtend` library recommends using Boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df_encoded = data_encoded.to_pandas()\n",
    "\n",
    "# Convert to boolean\n",
    "df_encoded = df_encoded.astype(bool)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to apply the Apriori algorithm to find association rules between the selected variables and life expectancy. We will set the minimum support to 0.1, which means that an itemset must appear in at least 10% of the transactions to be considered frequent. In our case, we have 190 countries in the dataset, so an itemset must have a support of (must appear in) at least 19 countries to be considered frequent. We think this is a reasonable threshold to find meaningful associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori algorithm with a minimum support of 0.1\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.1, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to find the association rules as confidently as possible. We will start with a minimum confidence threshold of 0.8, which means that the rule must be correct at least 80% of the time, but we will adjust this value based on the results obtained. Note that we are looking for rules that contain life expectancy as the consequent, since our experiment is focused on understanding the factors that influence life expectancy, so we will filter the rules accordingly.\n",
    "\n",
    "Let's start by counting the number of rules for each life expectancy category (low, medium, high) with a minimum confidence of 0.8, which means that the rule must be correct at least 80% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules with a minimum confidence of 0.8\n",
    "rules_80 = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.8)\n",
    "\n",
    "# Sort rules by confidence\n",
    "rules_80 = rules_80.sort_values(by=\"confidence\", ascending=False)\n",
    "\n",
    "# Show the number of rules for each category\n",
    "print(\"=== Rule Count by Life Expectancy Category ===\")\n",
    "for category in [\n",
    "    \"Life_expectancy_category_Low\",\n",
    "    \"Life_expectancy_category_Medium\",\n",
    "    \"Life_expectancy_category_High\",\n",
    "]:\n",
    "    count = rules_80[rules_80[\"consequents\"].apply(lambda x: category in x)].shape[0]\n",
    "    print(f\"{category.split('_')[-1].capitalize()}: {count} rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained 84 rules for the low life expectancy category and 26 rules for the high life expectancy category, but just 1 rule for the medium life expectancy category. This means that we can not currently provide a comprehensive analysis for the medium life expectancy category, so we will see what occurs when we decrease the minimum confidence threshold to 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules with a minimum confidence of 0.7\n",
    "rules_70 = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Sort rules by confidence\n",
    "rules_70 = rules_70.sort_values(by=\"confidence\", ascending=False)\n",
    "\n",
    "# Show the number of rules for each category\n",
    "print(\"=== Rule Count by Life Expectancy Category ===\")\n",
    "for category in [\n",
    "    \"Life_expectancy_category_Low\",\n",
    "    \"Life_expectancy_category_Medium\",\n",
    "    \"Life_expectancy_category_High\",\n",
    "]:\n",
    "    count = rules_70[rules_70[\"consequents\"].apply(lambda x: category in x)].shape[0]\n",
    "    print(f\"{category.split('_')[-1].capitalize()}: {count} rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a confidence threshold of 0.7, we have obtained 5 rules for the medium life expectancy category. We thnk that would be enough to provide a comprehensive analysis for the medium life expectancy category. On the other hand, we have obtained 131 rules for the low life expectancy category and 52 rules for the high life expectancy category. \n",
    "\n",
    "Now, we should select the most relevant rules for each life expectancy category. We will consider the 3 rules with the highest lift values, as lift measures how much more likely the antecedent and consequent are to co-occur compared to what would be expected if they were statistically independent. High lift values indicate a strong association between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Top 3 Rules by Lift per Category ===\")\n",
    "for category in [\n",
    "    \"Life_expectancy_category_Low\",\n",
    "    \"Life_expectancy_category_Medium\",\n",
    "    \"Life_expectancy_category_High\",\n",
    "]:\n",
    "    # Filter rules for the category\n",
    "    filtered_rules = rules_70[rules_70[\"consequents\"].apply(lambda x: category in x)]\n",
    "\n",
    "    # Sort the filtered rules by lift and get the top 3\n",
    "    top_3_rules = filtered_rules.sort_values(by=\"lift\", ascending=False).head(3)\n",
    "\n",
    "    # Print category and top 3 rules with their lift\n",
    "    print(f\"\\n{category.split('_')[-1].capitalize()} - Top 3 by Lift:\")\n",
    "    for index, row in top_3_rules.iterrows():\n",
    "        print(\n",
    "            f\"  Antecedents: {row['antecedents']} → Consequents: {row['consequents']} | Confidence: {row['confidence']:.2f} | Lift: {row['lift']:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained **association rules** reveal clear patterns in the factors influencing **low, medium, and high life expectancy**. By analyzing the top rules in each category, we can identify key socioeconomic and healthcare factors that contribute to life expectancy outcomes.  \n",
    "\n",
    "**Low Life Expectancy Category**  \n",
    "The top rules indicate that **low physician density**, **low GDP per capita**, and **low caloric ingestion** are strongly associated with **low life expectancy**. Specifically, the rule:  \n",
    "\n",
    "- **`{Few Physicians, Low Caloric Ingestion, Low Urbanization, Low CO2 Emissions} → {Low GDP per Capita, Low Life Expectancy}`**  \n",
    "  - *Confidence: 0.96 | Lift: 3.72*  \n",
    "\n",
    "confirms that limited access to healthcare and economic hardship contribute to reduced longevity. The presence of **low urbanization and low CO2 emissions** further supports the idea that these countries are less industrialized, with weaker infrastructure. The following two rules also emphasize these factors.\n",
    "\n",
    "**Medium Life Expectancy Category**  \n",
    "Countries in this category show **moderate improvements in GDP per capita and caloric ingestion** but still face challenges such as **out-of-pocket healthcare expenses**. The rule:  \n",
    "\n",
    "- **`{Medium Out-of-Pocket Healthcare Spending, Medium GDP per Capita} → {Medium Life Expectancy}`**  \n",
    "  - *Confidence: 0.81 | Lift: 2.10*  \n",
    "\n",
    "suggests that while economic conditions are better than in low-life-expectancy countries, the financial burden of healthcare may limit access to medical services. Similarly, the rule:  \n",
    "\n",
    "- **`{Medium GDP per Capita, Low CO2 Emissions, Moderate Caloric Ingestion} → {Medium Life Expectancy}`**  \n",
    "  - *Confidence: 0.73 | Lift: 1.91*  \n",
    "\n",
    "indicates that although food security is improving, these countries have not yet reached full industrialization.  \n",
    "\n",
    "**High Life Expectancy Category**  \n",
    "The strongest rules in this category highlight the role of **high GDP per capita**, **many physicians per capita**, and **low out-of-pocket healthcare costs** in promoting longevity. The rule:  \n",
    "\n",
    "- **`{High Caloric Ingestion, Low Out-of-Pocket Healthcare Spending, High GDP per Capita} → {Many Physicians, High Life Expectancy}`**  \n",
    "  - *Confidence: 0.86 | Lift: 4.21*  \n",
    "\n",
    "supports the idea that **strong healthcare infrastructure and financial accessibility** contribute to longer lifespans. Additionally, the rule:  \n",
    "\n",
    "- **`{High Caloric Ingestion, High GDP per Capita, High Urbanization,} → {Many Physicians, High Life Expectancy}`**  \n",
    "  - *Confidence: 0.78 | Lift: 3.90*  \n",
    "\n",
    "indicates that urbanized, economically developed nations tend to provide better healthcare access, further reinforcing high life expectancy.\n",
    "\n",
    "In short, the association rules confirm well-established relationships between economic development, healthcare accessibility, and longevity. **Low life expectancy** is linked to **poor healthcare infrastructure, economic hardship, and undernutrition**, whereas **high life expectancy** is driven by **wealth, strong healthcare systems, and urbanization**. **Medium-life-expectancy countries** show transitional characteristics, improving in some aspects but still facing barriers to healthcare access. These findings emphasize the importance of **economic growth, healthcare investment, and nutrition** in improving global life expectancy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "As a final addition, we can observe the average vales of these variables across the different life expectancy categories to visualize what we laid out in the association rules.\n",
    "\n",
    "We are going to normalize first because the difference in values is too large. We use the z-score normalization method because it is robust to outliers and will allow us to compare the variables on the same scale more easily. With this, we mean the scaling the variables via this method will provide a better representation of the data on each group of life expectancy. On the other hand, this method of scaling is also dangerous as on the visualization, the proportions will not be preserved with respect to the original data but, again, let us see the difference in which have lower or higher values on each group. To compensate this limitation, we will use as the lower bound of the visualization the lowest value in any column after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = data.with_columns(\n",
    "    (\n",
    "        pl.col(\"Out of pocket health expenditure\")\n",
    "        - pl.col(\"Out of pocket health expenditure\").mean()\n",
    "    )\n",
    "    / pl.col(\"Out of pocket health expenditure\")\n",
    "    .std()\n",
    "    .alias(\"Out of pocket health expenditure\"),\n",
    "    (pl.col(\"Physicians per thousand\") - pl.col(\"Physicians per thousand\").mean())\n",
    "    / pl.col(\"Physicians per thousand\").std().alias(\"Physicians per thousand\"),\n",
    "    (\n",
    "        pl.col(\"Daily total caloric ingestion\")\n",
    "        - pl.col(\"Daily total caloric ingestion\").mean()\n",
    "    )\n",
    "    / pl.col(\"Daily total caloric ingestion\")\n",
    "    .std()\n",
    "    .alias(\"Daily total caloric ingestion\"),\n",
    "    (pl.col(\"GDP per capita\") - pl.col(\"GDP per capita\").mean())\n",
    "    / pl.col(\"GDP per capita\").std().alias(\"GDP per capita\"),\n",
    "    (pl.col(\"CO2 emissions per capita\") - pl.col(\"CO2 emissions per capita\").mean())\n",
    "    / pl.col(\"CO2 emissions per capita\").std().alias(\"CO2 emissions per capita\"),\n",
    "    (\n",
    "        pl.col(\"Urban population percentage\")\n",
    "        - pl.col(\"Urban population percentage\").mean()\n",
    "    )\n",
    "    / pl.col(\"Urban population percentage\").std().alias(\"Urban population percentage\"),\n",
    ").drop([\"Life expectancy\", \"Unemployment rate\"])\n",
    "\n",
    "extended_dataset = pl.concat(\n",
    "    [\n",
    "        normalized_data,\n",
    "        discretized_data.select(\n",
    "            [\n",
    "                \"Life_expectancy_category\",\n",
    "            ]\n",
    "        ),\n",
    "    ],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "\n",
    "high_life_exp = extended_dataset.filter(\n",
    "    pl.col(\"Life_expectancy_category\") == \"High\"\n",
    ").drop([\"Life_expectancy_category\"])\n",
    "middle_life_exp = extended_dataset.filter(\n",
    "    pl.col(\"Life_expectancy_category\") == \"Medium\"\n",
    ").drop([\"Life_expectancy_category\"])\n",
    "low_life_exp = extended_dataset.filter(\n",
    "    pl.col(\"Life_expectancy_category\") == \"Low\"\n",
    ").drop([\"Life_expectancy_category\"])\n",
    "lowest_value = min(\n",
    "    [\n",
    "        min(high_life_exp.to_numpy().flatten()),\n",
    "        min(middle_life_exp.to_numpy().flatten()),\n",
    "        min(low_life_exp.to_numpy().flatten()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for name, color, group_data in zip(\n",
    "    (\"High\", \"Mid\", \"Low\"),\n",
    "    (\"green\", \"yellow\", \"red\"),\n",
    "    [high_life_exp, middle_life_exp, low_life_exp],\n",
    "):\n",
    "    mean_values = group_data.mean().to_pandas().values.flatten()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatterpolar(\n",
    "            r=mean_values,\n",
    "            theta=group_data.columns,\n",
    "            name=name,\n",
    "            fill=\"toself\",\n",
    "            line_color=color,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=True, range=[lowest_value, 1.2])),\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, the analysis reveals that life expectancy is strongly influenced by factors such as healthcare availability, economic conditions, nutrition, and urbanization. Countries with more physicians per capita, higher median salaries, and greater access to tertiary education tend to have longer life expectancies, as these factors improve healthcare access, nutrition, and living standards. Additionally, higher caloric intake from foods like dairy, eggs, and meat is associated with better nutrition and, consequently, longer lifespans. On the negative side, higher birth rates and infant mortality are linked to strained healthcare systems and poor living conditions, which contribute to shorter life expectancy. Rising living costs, indicated by a negative correlation with the Consumer Price Index, may further limit access to essential resources, making it harder for populations to maintain good health.\n",
    "\n",
    "The analysis also categorizes life expectancy into low, medium, and high categories, each shaped by distinct factors. In countries with low life expectancy, limited healthcare access, low GDP, and poor nutrition are primary contributors to shorter lifespans. These nations tend to have lower urbanization and infrastructure development. In contrast, medium life expectancy countries show moderate improvements in economic conditions but face challenges like out-of-pocket healthcare costs that restrict access to medical services. High life expectancy countries benefit from robust healthcare systems, high GDP, and low healthcare expenses, alongside high urbanization and better overall infrastructure. These findings underscore the importance of strong healthcare, economic development, and access to nutrition in promoting longevity, while highlighting the negative impact of inadequate resources on health outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q2: What factor set countries apart?\n",
    "\n",
    "In order to answer the question *What factor set countries apart?*, we will investigate the key factors that differentiate countries based on various indicators. By identifying the factors that set countries apart, we can gain insights into the unique characteristics of different nations, such as economic development, healthcare quality, and environmental sustainability.\n",
    "\n",
    "To to this we propose a clustering approach to group countries based on their characteristics and identify the factors that distinguish each cluster. Clustering is an unsupervised machine learning technique that groups similar data points together based on their features. By applying clustering to the dataset, we can identify patterns and relationships between countries, revealing the factors that set them apart.\n",
    "\n",
    "Understanding key differences between countries and grouping them is essential for policymakers, economists, and researchers to develop targeted strategies and policies that address the specific needs and challenges of each group. By analyzing global data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Before applying clustering algorithms, we need to select the features that will be used to group the countries. This is important because the choice of features will determine the characteristics that differentiate the countries in each cluster, and selecting noisy or irrelevant features can lead to suboptimal clustering results.\n",
    "\n",
    "Doing this feature selection implies:\n",
    "- Removing highly correlated variables that are also highly similar in meaning, as they may introduce multicollinearity issues and bias the clustering results.\n",
    "- Removing features which do not present enough variability across countries, as they may not contribute to distinguishing the countries in the clustering process.\n",
    "- Normalizing data to ensure that all features are on the same scale, as clustering algorithms are sensitive to the scale of the data, even more so when dealing with high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = cleaned_data.drop(\n",
    "    [\n",
    "        \"Country\",\n",
    "        \"Abbreviation\",\n",
    "        \"Code\",\n",
    "        \"Year\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "corr_data = corr_data.to_pandas()\n",
    "\n",
    "correlation_matrix = corr_data.corr(method=\"spearman\")\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(\n",
    "    data=correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5\n",
    ")\n",
    "plt.title(label=\"Spearmans Correlation Matrix\", fontdict={\"fontsize\": 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to drop so far:\n",
    "- Calorie ingestion. Too related to the GDP per capita as was also seen in one of the individual analyses.\n",
    "- Median Salary, as it is highly correlated with the GDP per capita.\n",
    "- CPI change. Too related to the CPI.\n",
    "- Fertility rate, Maternal mortality ratio, and infant mortality in favour of the birth rate as they all reflect similar aspects of demographic dynamics, poor access to healthcare and living conditions.\n",
    "- Longitude and Latitude, as they are not relevant for the clustering analysis.\n",
    "- Gasoline price, as it does not provide any additional information to the analysis.\n",
    "- Land Area, as it is not relevant for the clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned_data.drop(\n",
    "    [\n",
    "        \"Country\",\n",
    "        \"Abbreviation\",\n",
    "        \"Code\",\n",
    "        \"Year\",\n",
    "        \"CPI Change (%)\",\n",
    "        \"Fertility Rate\",\n",
    "        \"Maternal mortality ratio\",\n",
    "        \"Infant mortality\",\n",
    "        \"Daily calorie supply per person from other commodities\",\n",
    "        \"Daily calorie supply per person from alcoholic beverages\",\n",
    "        \"Daily calorie supply per person from sugar\",\n",
    "        \"Daily calorie supply per person from oils and fats\",\n",
    "        \"Daily calorie supply per person from meat\",\n",
    "        \"Daily calorie supply per person from fruits and vegetables\",\n",
    "        \"Daily calorie supply per person from starchy roots\",\n",
    "        \"Daily calorie supply per person from pulses\",\n",
    "        \"Daily calorie supply per person from cereals and grains\",\n",
    "        \"Daily calorie supply per person from dairy and eggs\",\n",
    "        \"Daily total caloric ingestion\",\n",
    "        \"Median Salary\",\n",
    "        \"Longitude\",\n",
    "        \"Latitude\",\n",
    "        \"Gasoline Price\",\n",
    "        \"Land Area(Km2)\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "corr_data = data.to_pandas()\n",
    "\n",
    "correlation_matrix = corr_data.corr(method=\"spearman\")\n",
    "plt.figure(figsize=(30, 25))\n",
    "sns.heatmap(\n",
    "    data=correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5\n",
    ")\n",
    "plt.title(label=\"Spearmans Correlation Matrix\", fontdict={\"fontsize\": 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if some features are still highly correlated, we will keep them for now as their semantical meaning is different and they could provide different insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing features with low variability\n",
    "\n",
    "We will use 0.1 as the threshold for the coefficient of variation to remove features with low variability as it is often used as a standard threshold to identify features with low variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1  # Adjust threshold as needed\n",
    "selector = VarianceThreshold(threshold)\n",
    "\n",
    "selector.fit(data.to_pandas())\n",
    "\n",
    "high_variance_indices = selector.get_support(indices=True)\n",
    "\n",
    "selected_data = data.to_pandas().iloc[:, high_variance_indices]\n",
    "\n",
    "print(f\"Dropped columns: {set(selected_data.columns.to_list()) - set(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_variance_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing data\n",
    "\n",
    "We will use the z-score normalization method to ensure that all features are on the same scale. This method is robust to outliers and will allow us to compare the features more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = data.with_columns(\n",
    "    *[\n",
    "        ((pl.col(col) - pl.col(col).mean()) / pl.col(col).std()).alias(col)\n",
    "        for col in data.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "normalized_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal number of clusters\n",
    "\n",
    "Before applying clustering algorithms, we need to determine the optimal number of clusters to use. This is important because the number of clusters will affect the interpretability and quality of the clustering results. We will use different methods to find the optimal number of clusters, such as the elbow method, silhouette score, and gap statistics, and then select the most appropriate number based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_statistic(X, k_max, n_replicates=10):\n",
    "    \"\"\"\n",
    "    Compute the Gap Statistic for a range of cluster numbers.\n",
    "\n",
    "    Parameters:\n",
    "    X: array-like, shape (n_samples, n_features)\n",
    "        The input data.\n",
    "    k_max: int\n",
    "        The maximum number of clusters to evaluate.\n",
    "    n_replicates: int\n",
    "        The number of bootstrap samples.\n",
    "\n",
    "    Returns:\n",
    "    gap_values: list\n",
    "        The calculated gap values for each k.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate reference data from a uniform distribution\n",
    "    def generate_reference_data(X):\n",
    "        return np.random.uniform(low=X.min(axis=0), high=X.max(axis=0), size=X.shape)\n",
    "\n",
    "    gap_values = []\n",
    "\n",
    "    # Loop over a range of k values (1 to k_max)\n",
    "    for k in range(1, k_max + 1):\n",
    "        # Fit KMeans to the original data\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(X)\n",
    "        original_inertia = kmeans.inertia_\n",
    "\n",
    "        # Compute the average inertia for the reference datasets\n",
    "        reference_inertia = []\n",
    "        for _ in range(n_replicates):\n",
    "            random_data = generate_reference_data(X)\n",
    "            kmeans.fit(random_data)\n",
    "            reference_inertia.append(kmeans.inertia_)\n",
    "\n",
    "        # Calculate the Gap statistic\n",
    "        gap = np.log(np.mean(reference_inertia)) - np.log(original_inertia)\n",
    "        gap_values.append(gap)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, k_max + 1), gap_values, marker=\"o\")\n",
    "    plt.title(\"Gap Statistic vs Number of Clusters\")\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"Gap Statistic\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return gap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "k_range = range(1, 11)\n",
    "for k in range(1, 30):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(normalized_data)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "elbow = KneeLocator(range(1, 30), sse, curve=\"convex\", direction=\"decreasing\").elbow\n",
    "\n",
    "# Silhouette Method\n",
    "silhouette_scores = []\n",
    "db_scores = []\n",
    "ch_scores = []\n",
    "for k in k_range[1:]:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(normalized_data)\n",
    "    sh_score = silhouette_score(normalized_data, kmeans.labels_)\n",
    "    db_score = davies_bouldin_score(normalized_data, kmeans.labels_)\n",
    "    ch_score = calinski_harabasz_score(normalized_data, kmeans.labels_)\n",
    "    silhouette_scores.append(sh_score)\n",
    "    db_scores.append(db_score)\n",
    "    ch_scores.append(ch_score)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(k_range[1:], silhouette_scores, marker=\"o\")\n",
    "plt.title(\"Silhouette Score vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(k_range[1:], db_scores, marker=\"o\")\n",
    "plt.title(\"Davies-Bouldin Score vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Davies-Bouldin Score\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(k_range[1:], ch_scores, marker=\"o\")\n",
    "plt.title(\"Calinski-Harabasz Score vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Calinski-Harabasz Score\")\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "optimal_silhouette = k_range[1:][np.argmax(silhouette_scores)]\n",
    "optimal_db = k_range[1:][np.argmin(db_scores)]\n",
    "optimal_ch = k_range[1:][np.argmax(ch_scores)]\n",
    "\n",
    "# Gap Statistics Method\n",
    "gap_values = compute_gap_statistic(normalized_data.to_numpy(), k_max=10)\n",
    "optimal_gap = np.argmax(gap_values) + 1\n",
    "\n",
    "print(f\"Elbow Method suggests {elbow} clusters.\")\n",
    "print(f\"Silhouette Method suggests {optimal_silhouette} clusters.\")\n",
    "print(f\"Gap Statistics Method suggests {optimal_gap} clusters.\")\n",
    "print(f\"Davies-Bouldin Method suggests {optimal_db} clusters.\")\n",
    "print(f\"Calinski-Harabasz Method suggests {optimal_ch} clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most supported number of clusters is 2, so we will use this number to perform the non-hierarchical clustering analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying clustering techniques\n",
    "\n",
    "We will apply K-means clustering which is popular clustering algorithm that partitions the data into K clusters based on the mean distance between data points and cluster centroids.\n",
    "\n",
    "In our case density based clustering does not make sense as we want to find similar countries based on their characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "kmeans.fit(normalized_data)\n",
    "\n",
    "cluster_labels = kmeans.predict(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data = cleaned_data.with_columns(\n",
    "    pl.Series(\"Cluster\", cluster_labels).alias(\"Cluster\"),\n",
    ")\n",
    "\n",
    "fig = px.choropleth(\n",
    "    clustered_data.to_pandas(),\n",
    "    locations=\"Country\",\n",
    "    locationmode=\"country names\",\n",
    "    color=\"Cluster\",\n",
    "    hover_name=\"Country\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    projection=\"natural earth\",\n",
    "    title=\"Cluster\",\n",
    ")\n",
    "fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 50, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply Mann-Whitney U test to determine if the clusters are significantly different in terms of the features. This way we can filter out the features that are not different enough between the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "cluster_0 = clustered_data.filter(pl.col(\"Cluster\") == 0)\n",
    "cluster_1 = clustered_data.filter(pl.col(\"Cluster\") == 1)\n",
    "\n",
    "res = {}\n",
    "\n",
    "for col in cleaned_data.drop([\"Country\", \"Abbreviation\", \"Year\", \"Code\"]).columns:\n",
    "    data_c0 = cluster_0[col].to_list()\n",
    "    data_c1 = cluster_1[col].to_list()\n",
    "\n",
    "    stat, p_value = stats.mannwhitneyu(data_c0, data_c1, alternative=\"two-sided\")\n",
    "\n",
    "    res[col] = {\"U-statistic\": stat, \"p-value\": p_value}\n",
    "\n",
    "significant_columns = []\n",
    "for col, values in res.items():\n",
    "    if values[\"p-value\"] < 0.05:\n",
    "        print(f\"{col}: U={values['U-statistic']}, p={values['p-value']} (Significant)\")\n",
    "        significant_columns.append(col)\n",
    "    else:\n",
    "        print(\n",
    "            f\"{col}: U={values['U-statistic']}, p={values['p-value']} (Not Significant)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data_pd = (\n",
    "    clustered_data.drop([\"Country\", \"Abbreviation\", \"Code\", \"Year\"])\n",
    "    .with_columns(\n",
    "        *[\n",
    "            ((pl.col(col) - pl.col(col).mean()) / pl.col(col).std()).alias(col)\n",
    "            for col in clustered_data.drop(\n",
    "                [\"Country\", \"Abbreviation\", \"Code\", \"Year\", \"Cluster\"]\n",
    "            ).columns\n",
    "        ]\n",
    "    )\n",
    "    .select([*significant_columns, \"Cluster\"])\n",
    "    .to_pandas()\n",
    ")\n",
    "clustered_data_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a pivot table with colname, cluster and colvalue\n",
    "pivot_table = clustered_data_pd.melt(\n",
    "    id_vars=\"Cluster\", var_name=\"Feature\", value_name=\"Value\"\n",
    ")\n",
    "pivot_table.head()\n",
    "\n",
    "# remove outliers\n",
    "pivot_table = pivot_table[np.abs(stats.zscore(pivot_table[\"Value\"])) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(significant_columns), 5):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for col in significant_columns[i : i + 5]:\n",
    "        # add two traces for each cluster\n",
    "        for cluster, pos, color in zip(\n",
    "            range(2), (\"positive\", \"negative\"), (\"blue\", \"orange\")\n",
    "        ):\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    x=pivot_table[\n",
    "                        (pivot_table[\"Cluster\"] == cluster)\n",
    "                        & (pivot_table[\"Feature\"] == col)\n",
    "                    ][\"Feature\"],\n",
    "                    y=pivot_table[\n",
    "                        (pivot_table[\"Cluster\"] == cluster)\n",
    "                        & (pivot_table[\"Feature\"] == col)\n",
    "                    ][\"Value\"],\n",
    "                    legendgroup=f\"Cluster {cluster}\",\n",
    "                    name=f\"Cluster {cluster}\",\n",
    "                    scalegroup=f\"Cluster {cluster}\",\n",
    "                    scalemode=\"count\",\n",
    "                    side=pos,\n",
    "                    line_color=color,\n",
    "                    points=\"outliers\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_traces(meanline_visible=True)\n",
    "    fig.update_layout(violingap=0, violinmode=\"overlay\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Results\n",
    "\n",
    "The clustering analysis produced two well‐defined groups of countries that exhibit significant differences across several key dimensions. Below is a summary of the main findings:\n",
    "\n",
    "- **Health and Demographics:**  \n",
    "  One cluster stands out with markedly lower values in indicators such as infant mortality, birth rate, fertility rate, and maternal mortality. These patterns suggest better healthcare systems and living conditions, which in turn are associated with higher life expectancy.\n",
    "\n",
    "- **Economic and Nutritional Factors:**  \n",
    "  Countries in the superior cluster show much higher GDP per capita and greater daily caloric intake. These economic advantages likely contribute to improved nutrition and overall wellbeing. Additionally, a higher number of physicians per thousand inhabitants further reinforces the role of accessible healthcare services in this group.\n",
    "\n",
    "- **Urbanization and Industrialization:**  \n",
    "  The analysis also indicates that the cluster with better health outcomes tends to be more urbanized. These nations exhibit higher CO2 emissions per capita, which can be seen as a proxy for industrial activity and overall economic development. Although higher emissions often raise environmental concerns, in this context they align with improved infrastructure and accessible public services.\n",
    "\n",
    "- **Educational Opportunities:**  \n",
    "  An increased enrollment in tertiary education in the high-performing cluster underscores the close link between a strong economy, better healthcare, and enhanced educational prospects.\n",
    "\n",
    "Overall, the results confirm that countries separating into one cluster typically benefit from stronger healthcare infrastructure, economic development, and modern urbanization—all contributing to higher life expectancy and better overall standards of living. The statistical tests (e.g., the Mann–Whitney U test) further confirm that these differences are significant, suggesting clear pathways for policymakers and researchers to target improvements where needed.### Understanding results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Final insigths and recommendations to policymakers, healthcare professionals, and economists to improve public health strategies and resource allocation are (Based on both questions analysis):\n",
    "\n",
    "- **Invest in Healthcare Access:**  \n",
    "  The strong positive correlation between life expectancy and indicators such as the number of physicians per thousand inhabitants and lower infant mortality suggests that improving healthcare infrastructure should be a top priority. Expanding access to healthcare professionals, preventive care, and early treatment services can lead to significant improvements in overall health outcomes.\n",
    "\n",
    "- **Support Economic and Nutritional Improvements:**  \n",
    "  Higher GDP per capita and better daily caloric intake were associated with longer life expectancy. Investments that boost economic growth (even if gradual) can allow countries to allocate more resources to healthcare, education, and nutrition. Improving food security and nutritional quality is essential to support a healthier population.\n",
    "\n",
    "- **Focus on Reducing Birth and Infant Mortality Rates:**  \n",
    "  The negative associations observed with higher birth rates and infant mortality indicate that family planning services, maternal health programs, and improved neonatal care can dramatically enhance life expectancy. Implementing public health campaigns that address these issues may also contribute to slowing population pressures on underfunded healthcare systems.\n",
    "\n",
    "- **Enhance Educational Opportunities:**  \n",
    "  Although the correlation between tertiary education levels and life expectancy might be partially confounded by economic development, countries that invest in education tend to see broader social and health benefits. Promoting universal education can empower populations to make healthier life choices and improve economic prospects.\n",
    "\n",
    "Overall, while there is no single “quick fix,” a balanced focus on strengthening healthcare infrastructure, supporting economic development, improving nutrition, reducing excessive birth rates, and expanding educational opportunities will provide a multilateral strategy to uplift overall health and life expectancy in underdeveloped countries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
